STAVKI Value System — Детальный План Улучшений
Версия: v1.0 | Дата: 2026-01-29

Обзор
План разделён на 3 этапа по приоритетности. Каждый этап завершается тестированием и валидацией. Можно применять поэтапно — каждый этап автономен.

Этап 1: Честность и Стабильность
Цель: Устранить расхождения train/inference, добавить базовые гарантии качества.

1.1 Единый протокол фич для ансамбля (Task A)
Проблема: CatBoost обучается с ColumnTransformer, но при inference в 
ensemble_predictor.py
 используется Pool напрямую. Это может вызвать рассогласование фич.

Файлы для изменения:
[MODIFY] 
train_catboost.py
Сохранять preprocessor (ColumnTransformer) вместе с моделью в pickle
Добавить версию схемы фич в метаданные
[MODIFY] 
ensemble_predictor.py
Загружать и применять preprocessor перед CatBoost
Добавить проверку совместимости фич
[MODIFY] 
loader.py
Добавить метод get_preprocessor() для загрузки трансформера
Тестирование
# Запустить существующие тесты
pytest tests/test_ml_live_integration.py -v
# Новый тест: проверить совместимость фич train/inference
pytest tests/test_feature_alignment.py -v  # Создать если нет
Критерий успеха: Фичи на входе в CatBoost идентичны при train и inference.

1.2 Добавить Elo-фичи в тренировочный датасет (Task C)
Проблема: 
live_extractor.py
 использует Elo (строки 109-112), но 
engineer_multi_league_features.py
 НЕ добавляет Elo в датасет для обучения.

Файлы для изменения:
[MODIFY] 
engineer_multi_league_features.py
Импортировать 
calculate_elo_for_dataset
 из 
elo.py
Добавить Elo-фичи после загрузки данных:
HomeEloBefore, AwayEloBefore, EloDiff
Убедиться, что Elo рассчитывается per-league (не смешивать команды из разных лиг)
# Пример изменения в engineer_features():
from src.features.elo import calculate_elo_for_dataset
def engineer_features(df):
    # Существующий код...
    
    # NEW: Добавить Elo per-league
    df_with_elo = df.groupby('League', group_keys=False).apply(
        lambda g: calculate_elo_for_dataset(g.copy())
    )
    # ...
Тестирование
# 1. Запустить feature engineering
python scripts/engineer_multi_league_features.py
# 2. Проверить наличие Elo-колонок
python -c "import pandas as pd; df=pd.read_csv('data/processed/multi_league_features_2021_2024.csv'); print([c for c in df.columns if 'Elo' in c])"
# Ожидаемый вывод: ['HomeEloBefore', 'AwayEloBefore', 'EloDiff', ...]
# 3. Запустить тесты
pytest tests/test_features.py -v
Критерий успеха: Датасет содержит Elo-колонки, значения корректны (1400–1600 диапазон).

1.3 Разделить Train/Val/Calibration/Test (Task E)
Проблема: В 
train_simple_ensemble.py
 калибровка и валидация используют один и тот же val-сет (строки 108-210), что может переоценивать качество.

Файлы для изменения:
[MODIFY] 
train_simple_ensemble.py
Изменить сплиты с 70/85/100 на 60/75/85/100:

# BEFORE:
train_end = int(n * 0.70)
val_end = int(n * 0.85)
# AFTER:
train_end = int(n * 0.60)
cal_end = int(n * 0.75)   # NEW: Calibration set
val_end = int(n * 0.85)
train_df = df.iloc[:train_end].copy()
cal_df = df.iloc[train_end:cal_end].copy()  # NEW
val_df = df.iloc[cal_end:val_end].copy()
test_df = df.iloc[val_end:].copy()
Калибровать на cal_df
Валидировать на val_df
Финальный тест на test_df
Тестирование
# 1. Переобучить ансамбль
python scripts/train_simple_ensemble.py
# 2. Проверить логи — должно быть 4 сета
# "Train: X, Cal: Y, Val: Z, Test: W"
# 3. Сравнить метрики val vs test — не должно быть большого gap
Критерий успеха: Brier на val и test отличаются менее чем на 5%.

1.4 Внедрить Time-series CV (Task F)
Проблема: Один сплит по времени недостаточен для стабильной оценки.

Файлы для изменения:
[NEW] 
time_series_cv.py
Создать утилиту TimeSeriesFold с 4-6 фолдами
Каждый фолд: train на прошлом, test на будущем
Никогда не смешивать будущее в train
[MODIFY] 
train_model.py
Добавить опцию --cv-folds 5 для кросс-валидации
Логировать метрики по каждому фолду и среднее
Тестирование
# 1. Запустить с CV
python scripts/train_model.py --cv-folds 5
# 2. Проверить, что нет leakage
pytest tests/test_features.py::TestDataLeakagePrevention -v
Критерий успеха: std(metrics across folds) < 0.02.

1.5 Унифицировать логирование (Task I)
Проблема: Скрипты используют basicConfig вместо централизованного 
logging_setup.py
.

Файлы для изменения:
[MODIFY] Все скрипты в scripts/
Заменить:

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
На:

from src.logging_setup import get_logger
logger = get_logger(__name__)
Список файлов (топ-приоритет):

train_simple_ensemble.py
train_poisson_model.py
train_catboost.py
run_value_finder.py
Тестирование
# 1. Запустить пайплайн
python scripts/run_value_finder.py --sport soccer_epl --dry-run
# 2. Проверить логи в едином формате
cat audit_pack/RUN_LOGS/scheduler.log | head -20
Критерий успеха: Все логи имеют единый формат (timestamp, level, module).

1.6 Добавить мини-тесты качества (Task K)
Проблема: Нет автоматизированных проверок целостности пайплайна.

Файлы для изменения:
[NEW] 
test_pipeline_sanity.py
Тесты:

Prob sum = 1.0: Все вероятности суммируются к 1.0 ± 0.001
Feature order: Порядок фич train == inference
No NaN: Предсказания не содержат NaN
Odds sanity: odds > 1.01
def test_probability_sum():
    """Probabilities must sum to 1.0."""
    probs = model.predict(X_test)
    sums = probs.sum(axis=1)
    assert np.allclose(sums, 1.0, atol=0.001)
def test_feature_order_match():
    """Train and inference feature order must match."""
    train_features = model.get_feature_names()
    inference_features = extractor.get_feature_names()
    assert train_features == inference_features
Тестирование
pytest tests/test_pipeline_sanity.py -v
Критерий успеха: Все 4 теста проходят.

✅ Валидация Этапа 1
После завершения всех задач:

# Полный прогон тестов
pytest tests/ -v --tb=short
# Dry-run пайплайна
python scripts/run_value_finder.py --sport soccer_epl --dry-run --global-mode
# Проверить метрики
python scripts/validate_metrics_comprehensive.py
Критерии готовности к Этапу 2:

 Все тесты проходят (pytest exit code 0)
 Elo-фичи присутствуют в train данных
 Brier score не ухудшился (< 0.22)
Этап 2: Рост Качества
Цель: Улучшить калибровку и добавить новые сигналы.

2.1 Per-league baseline для Poisson (Task D)
Проблема: Единый baseline (goals per game) для всех лиг создаёт смещение.

Файлы для изменения:
[MODIFY] 
train_poisson_model.py
В PoissonMatchPredictor.fit():

# BEFORE: Единый baseline
self.league_avg_goals = df['FTHG'].mean() + df['FTAG'].mean()
# AFTER: Per-league baseline
self.league_baselines = df.groupby('League').apply(
    lambda g: (g['FTHG'].mean() + g['FTAG'].mean()) / 2
).to_dict()
В 
predict_match()
:

league = match.get('League', 'default')
baseline = self.league_baselines.get(league, self.default_baseline)
Тестирование
# 1. Переобучить Poisson
python scripts/train_poisson_model.py
# 2. Сравнить Brier до/после
# Ожидаемое улучшение: 0.5-1%
# 3. Запустить тесты
pytest tests/test_poisson_model.py -v
2.2 Тюнинг time_decay_rate (Task G)
Текущее значение: time_decay_rate=0.003 (фиксированное).

Изменения:
[MODIFY] 
train_poisson_model.py
Добавить grid search:

decay_rates = [0.001, 0.002, 0.003, 0.005, 0.01]
best_rate, best_brier = None, float('inf')
for rate in decay_rates:
    model = PoissonMatchPredictor(time_decay_rate=rate)
    model.fit(train_df)
    brier = evaluate_on_val(model, val_df)
    if brier < best_brier:
        best_rate, best_brier = rate, brier
Тестирование
python scripts/train_poisson_model.py --tune-decay
# Логи покажут лучший rate
2.3 Интеграция Sentiment (Task H)
Статус: 
sentiment_fetcher.py
 существует, но фичи не используются в train.

Файлы для изменения:
[MODIFY] 
engineer_multi_league_features.py
Добавить sentiment-фичи (или нейтральные значения = 0 при отсутствии)
[NEW] 
eval_sentiment_impact.py
A/B сравнение: модель с sentiment vs без
Если нет улучшения Brier > 0.5% — удалить sentiment
Тестирование
# A/B тест
python scripts/eval_sentiment_impact.py
Критерий: Если Brier не улучшился — удалить sentiment из пайплайна.

2.4 Бэктест как главный KPI (Task L)
[NEW] 
run_backtest.py
Единый отчёт:

ROI (%)
Max Drawdown (%)
Sharpe Ratio
Win Rate
Total Bets
python scripts/run_backtest.py --start 2024-01-01 --end 2024-12-31 --bankroll 1000
✅ Валидация Этапа 2
# Сравнение метрик до/после
python scripts/validate_metrics_comprehensive.py
# Бэктест
python scripts/run_backtest.py --start 2023-01-01 --end 2024-12-31
Критерии готовности к Этапу 3:

 Brier улучшился на 1-2%
 ROI в бэктесте > 0%
Этап 3: Продуктовый Уровень
Цель: Автоматизация и продвинутые фичи.

3.1 Авто-переобучение с гейтами (Task N)
[NEW] 
retrain_pipeline.py
Пайплайн:

Загрузить новые данные
Feature engineering
Train модели
Evaluate на holdout
Gate: если Brier > threshold — reject
Deploy (symlink latest)
3.2 Feature Store (Task M)
[NEW] 
feature_store.py
Снапшоты фич по датам
Версионирование
Point-in-time запросы
3.3 Odds Tracking (Task Q)
Использовать 
odds_tracker.py
 для сбора истории линий и line movement сигналов.

3.4 Explainability — SHAP (Task R)
[NEW] 
explain_predictions.py
import shap
explainer = shap.TreeExplainer(catboost_model)
shap_values = explainer(X_test)
shap.summary_plot(shap_values)
Общий Verification Plan
Автоматические тесты
Тест	Команда	Что проверяет
Unit tests	pytest tests/ -v	Все модули
Leakage	pytest tests/test_features.py::TestDataLeakagePrevention -v	Нет утечек
Calibration	pytest tests/test_calibration_sums_to_one.py -v	Prob sum = 1
E2E	pytest tests/test_e2e_pipeline.py -v	Полный пайплайн
Ручная валидация
Dry-run пайплайна:

python scripts/run_value_finder.py --sport soccer_epl --dry-run --top 5
Ожидаемый результат: 5 ставок с EV > 8%, prob sum ≈ 1.0

Telegram test:

python scripts/run_value_finder.py --sport soccer_epl --now --telegram
Ожидаемый результат: сообщение в Telegram-боте

IMPORTANT

Применять этапы последовательно. После каждого этапа — полный прогон pytest tests/.